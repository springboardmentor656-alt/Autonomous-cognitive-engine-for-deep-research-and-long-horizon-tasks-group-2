# ğŸ¤– Agentic AI using LangChain + Ollama + LangSmith

This project is a beginner-friendly **Agentic AI** setup using:
- **LangChain** for agent logic
- **Ollama** for running LLMs locally (llama3 / tinyllama)
- **LangSmith** for tracing and debugging
- **Python** as backend


## âš™ï¸ Prerequisites

- Python  3.11
- Ollama installed  
  ğŸ‘‰ https://ollama.com/download

Verify Ollama:
```bash
ollama --version
This project is a beginner-friendly Agentic AI system built using modern LLM tooling. It demonstrates how to design agents, run local models, trace executions, and evaluate outputs using LangSmith.

ğŸš€ Tech Stack & Tools ğŸ§  Core Frameworks

LangChain â€“ Agent logic, prompt handling, chains, and tools

LangGraph â€“ Graph-based agent execution and state management

Pydantic â€“ Data validation, schemas, and structured outputs

ğŸ¤– Large Language Models (LLMs)

Ollama â€“ Run LLMs locally (llama3, tinyllama)

Groq â€“ Fast hosted inference (optional)

OpenAI â€“ Cloud LLM provider (optional)

Anthropic â€“ Claude models support (optional) Observability & Evaluation

LangSmith

Tracing agent runs

Debugging prompts & graphs

Running experiments on datasets

Custom evaluation pipelines